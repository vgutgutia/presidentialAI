#!/usr/bin/env python3
"""
Advanced Training Script - Maximum Performance
- Better architecture with attention
- Advanced loss functions (Dice + Focal + CE)
- Data augmentation
- Learning rate finder
- Better evaluation metrics
- Optimized for speed and accuracy
"""

import os
import sys
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from pathlib import Path
from tqdm import tqdm
import time

# Configuration
SCRIPT_DIR = Path(__file__).parent
PROJECT_ROOT = SCRIPT_DIR.parent
OUTPUT_DIR = PROJECT_ROOT / "outputs" / "models"
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

BATCH_SIZE = 16  # Larger batch for stability
EPOCHS = 100  # More epochs
LEARNING_RATE = 1e-3  # Higher initial LR
WEIGHT_DECAY = 1e-4
IN_CHANNELS = 11
NUM_CLASSES = 2

# Device
if torch.cuda.is_available():
    DEVICE = "cuda"
    print(f"Using CUDA GPU: {torch.cuda.get_device_name(0)}")
elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
    DEVICE = "mps"
    print("Using Apple Silicon MPS")
else:
    DEVICE = "cpu"
    print("Using CPU")


class AdvancedSyntheticDataset(Dataset):
    """Enhanced synthetic dataset with better variety."""
    
    def __init__(self, num_samples=2000, image_size=256, augment=True):
        self.num_samples = num_samples
        self.image_size = image_size
        self.augment = augment
        
    def __len__(self):
        return self.num_samples
    
    def __getitem__(self, idx):
        # Generate more realistic satellite imagery
        image = np.random.rand(11, self.image_size, self.image_size).astype(np.float32) * 0.2
        
        # Add realistic water patterns
        for i in range(11):
            y, x = np.ogrid[:self.image_size, :self.image_size]
            
            # Multiple water regions
            for _ in range(np.random.randint(1, 4)):
                cy = np.random.randint(0, self.image_size)
                cx = np.random.randint(0, self.image_size)
                dist = np.sqrt((x - cx)**2 + (y - cy)**2)
                image[i] += 0.15 * np.exp(-dist**2 / (2 * (self.image_size/3)**2))
            
            # Add realistic noise
            image[i] += np.random.randn(self.image_size, self.image_size).astype(np.float32) * 0.015
        
        # Generate more realistic debris masks
        mask = np.zeros((self.image_size, self.image_size), dtype=np.int64)
        
        # Ensure 80% of images have debris
        has_debris = (idx % 5 != 0)
        
        if has_debris:
            n_patches = np.random.randint(2, 10)
            for _ in range(n_patches):
                cy = np.random.randint(20, self.image_size - 20)
                cx = np.random.randint(20, self.image_size - 20)
                size = np.random.randint(5, 35)
                
                # Create more realistic debris shapes
                y, x = np.ogrid[:self.image_size, :self.image_size]
                dist = np.sqrt((x - cx)**2 + (y - cy)**2)
                
                # Elliptical shapes
                angle = np.random.uniform(0, 2*np.pi)
                cos_a, sin_a = np.cos(angle), np.sin(angle)
                dx = (x - cx) * cos_a + (y - cy) * sin_a
                dy = -(x - cx) * sin_a + (y - cy) * cos_a
                ellipse_dist = np.sqrt((dx / (size * 0.8))**2 + (dy / size)**2)
                mask[ellipse_dist < 1.0] = 1
        
        # Data augmentation
        if self.augment:
            if np.random.rand() > 0.5:
                # Horizontal flip
                image = np.flip(image, axis=2).copy()
                mask = np.flip(mask, axis=1).copy()
            if np.random.rand() > 0.5:
                # Vertical flip
                image = np.flip(image, axis=1).copy()
                mask = np.flip(mask, axis=0).copy()
            if np.random.rand() > 0.5:
                # Rotate 90 degrees
                k = np.random.randint(1, 4)
                image = np.rot90(image, k, axes=(1, 2)).copy()
                mask = np.rot90(mask, k, axes=(0, 1)).copy()
        
        return torch.from_numpy(image.copy()), torch.from_numpy(mask.copy())


class SEBlock(nn.Module):
    """Squeeze-and-Excitation block for channel attention."""
    
    def __init__(self, channels, reduction=16):
        super().__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.fc = nn.Sequential(
            nn.Linear(channels, channels // reduction, bias=False),
            nn.ReLU(inplace=True),
            nn.Linear(channels // reduction, channels, bias=False),
            nn.Sigmoid()
        )
        
    def forward(self, x):
        B, C, _, _ = x.size()
        y = self.avg_pool(x).reshape(B, C)
        y = self.fc(y).reshape(B, C, 1, 1)
        return x * y.expand_as(x)


class AdvancedUNet(nn.Module):
    """Advanced U-Net with attention and better architecture."""
    
    def __init__(self, in_channels=11, num_classes=2):
        super().__init__()
        
        # Encoder with SE blocks
        self.enc1 = self._make_encoder_block(in_channels, 64)
        self.se1 = SEBlock(64)
        self.enc2 = self._make_encoder_block(64, 128)
        self.se2 = SEBlock(128)
        self.enc3 = self._make_encoder_block(128, 256)
        self.se3 = SEBlock(256)
        self.enc4 = self._make_encoder_block(256, 512)
        self.se4 = SEBlock(512)
        
        # Bottleneck
        self.bottleneck = self._make_encoder_block(512, 1024)
        self.se_bottleneck = SEBlock(1024)
        
        # Decoder with SE blocks
        self.up4 = nn.ConvTranspose2d(1024, 512, 2, 2)
        self.dec4 = self._make_decoder_block(1024, 512)
        self.se_dec4 = SEBlock(512)
        
        self.up3 = nn.ConvTranspose2d(512, 256, 2, 2)
        self.dec3 = self._make_decoder_block(512, 256)
        
        self.up2 = nn.ConvTranspose2d(256, 128, 2, 2)
        self.dec2 = self._make_decoder_block(256, 128)
        
        self.up1 = nn.ConvTranspose2d(128, 64, 2, 2)
        self.dec1 = self._make_decoder_block(128, 64)
        
        # Output
        self.out = nn.Sequential(
            nn.Conv2d(64, 32, 3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, num_classes, 1)
        )
        
        self.pool = nn.MaxPool2d(2)
        self.dropout = nn.Dropout2d(0.2)
    
    def _make_encoder_block(self, in_ch, out_ch):
        return nn.Sequential(
            nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False),
            nn.BatchNorm2d(out_ch),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False),
            nn.BatchNorm2d(out_ch),
            nn.ReLU(inplace=True),
        )
    
    def _make_decoder_block(self, in_ch, out_ch):
        return nn.Sequential(
            nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False),
            nn.BatchNorm2d(out_ch),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False),
            nn.BatchNorm2d(out_ch),
            nn.ReLU(inplace=True),
        )
    
    def forward(self, x):
        # Encoder
        e1 = self.enc1(x)
        e1 = self.se1(e1)
        e2 = self.enc2(self.pool(e1))
        e2 = self.se2(e2)
        e3 = self.enc3(self.pool(e2))
        e3 = self.se3(e3)
        e4 = self.enc4(self.pool(e3))
        e4 = self.se4(e4)
        
        # Bottleneck
        b = self.bottleneck(self.pool(e4))
        b = self.se_bottleneck(b)
        b = self.dropout(b)
        
        # Decoder
        d4 = self.dec4(torch.cat([self.up4(b), e4], dim=1))
        d4 = self.se_dec4(d4)
        d3 = self.dec3(torch.cat([self.up3(d4), e3], dim=1))
        d2 = self.dec2(torch.cat([self.up2(d3), e2], dim=1))
        d1 = self.dec1(torch.cat([self.up1(d2), e1], dim=1))
        
        return self.out(d1)


class DiceLoss(nn.Module):
    """Dice Loss for segmentation."""
    
    def __init__(self, smooth=1.0):
        super().__init__()
        self.smooth = smooth
    
    def forward(self, inputs, targets):
        # Get probabilities for class 1
        probs = F.softmax(inputs, dim=1)[:, 1]  # (B, H, W)
        
        # Flatten
        probs = probs.contiguous().reshape(-1)
        targets = targets.contiguous().reshape(-1).float()
        
        # Dice coefficient
        intersection = (probs * targets).sum()
        dice = (2. * intersection + self.smooth) / (probs.sum() + targets.sum() + self.smooth)
        
        return 1 - dice


class CombinedLoss(nn.Module):
    """Combined loss: Dice + Focal + Weighted CE."""
    
    def __init__(self, class_weights=None, alpha=0.25, gamma=2.0):
        super().__init__()
        self.dice_loss = DiceLoss()
        self.focal_loss = FocalLoss(alpha=alpha, gamma=gamma)
        self.ce_loss = nn.CrossEntropyLoss(weight=class_weights)
    
    def forward(self, inputs, targets):
        dice = self.dice_loss(inputs, targets)
        focal = self.focal_loss(inputs, targets)
        ce = self.ce_loss(inputs, targets)
        
        # Weighted combination
        return 0.4 * dice + 0.4 * focal + 0.2 * ce


class FocalLoss(nn.Module):
    """Focal Loss for class imbalance."""
    
    def __init__(self, alpha=0.25, gamma=2.0):
        super().__init__()
        self.alpha = alpha
        self.gamma = gamma
    
    def forward(self, inputs, targets):
        ce_loss = F.cross_entropy(inputs, targets, reduction='none')
        pt = torch.exp(-ce_loss)
        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss
        return focal_loss.mean()


def calculate_class_weights(dataset, num_classes=2, num_samples=500):
    """Calculate class weights."""
    total_pixels = 0
    class_counts = np.zeros(num_classes)
    
    print("Calculating class weights...")
    for i in tqdm(range(min(num_samples, len(dataset))), desc="Sampling"):
        _, mask = dataset[i]
        mask_np = mask.numpy()
        total_pixels += mask_np.size
        for c in range(num_classes):
            class_counts[c] += np.sum(mask_np == c)
    
    class_weights = total_pixels / (num_classes * class_counts + 1e-8)
    class_weights = class_weights / class_weights.sum() * num_classes
    
    print(f"Class distribution: {class_counts}")
    print(f"Class weights: {class_weights}")
    
    return torch.FloatTensor(class_weights).to(DEVICE)


def train():
    print("=" * 60)
    print("ðŸš€ ADVANCED Training - Maximum Performance")
    print("=" * 60)
    print(f"Device: {DEVICE}")
    print(f"Epochs: {EPOCHS}")
    print(f"Batch size: {BATCH_SIZE}")
    print(f"Learning rate: {LEARNING_RATE}")
    print()
    
    # Create datasets
    print("Creating training data...")
    train_dataset = AdvancedSyntheticDataset(num_samples=2000, augment=True)
    val_dataset = AdvancedSyntheticDataset(num_samples=400, augment=False)
    
    train_loader = DataLoader(
        train_dataset,
        batch_size=BATCH_SIZE,
        shuffle=True,
        num_workers=0,
        pin_memory=False,  # MPS doesn't support pin_memory
    )
    val_loader = DataLoader(
        val_dataset,
        batch_size=BATCH_SIZE,
        shuffle=False,
        num_workers=0,
        pin_memory=False,  # MPS doesn't support pin_memory
    )
    
    print(f"Train samples: {len(train_dataset)}")
    print(f"Val samples: {len(val_dataset)}")
    print()
    
    # Calculate class weights
    class_weights = calculate_class_weights(train_dataset)
    print()
    
    # Create model
    print("Initializing advanced model...")
    model = AdvancedUNet(in_channels=IN_CHANNELS, num_classes=NUM_CLASSES)
    model = model.to(DEVICE)
    
    n_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"Model parameters: {n_params:,}")
    print()
    
    # Optimizer with warmup
    optimizer = torch.optim.AdamW(
        model.parameters(),
        lr=LEARNING_RATE,
        weight_decay=WEIGHT_DECAY,
        betas=(0.9, 0.999)
    )
    
    # Learning rate scheduler with warmup
    def lr_lambda(epoch):
        if epoch < 10:  # Warmup
            return (epoch + 1) / 10
        else:  # Cosine annealing
            return 0.5 * (1 + np.cos(np.pi * (epoch - 10) / (EPOCHS - 10)))
    
    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)
    
    # Combined loss
    criterion = CombinedLoss(class_weights=class_weights)
    
    # Training loop
    print("Starting training...")
    print("=" * 60)
    
    best_f1 = 0.0
    best_iou = 0.0
    best_loss = float('inf')
    patience = 15
    patience_counter = 0
    
    train_times = []
    eval_times = []
    
    for epoch in range(EPOCHS):
        epoch_start = time.time()
        
        # Training
        model.train()
        train_loss = 0
        
        pbar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{EPOCHS}")
        for images, masks in pbar:
            images = images.to(DEVICE, non_blocking=True)
            masks = masks.to(DEVICE, non_blocking=True)
            
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, masks)
            loss.backward()
            
            # Gradient clipping
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            
            optimizer.step()
            
            train_loss += loss.item()
            pbar.set_postfix({'loss': f'{loss.item():.4f}'})
        
        avg_train_loss = train_loss / len(train_loader)
        train_time = time.time() - epoch_start
        
        # Validation
        eval_start = time.time()
        model.eval()
        val_loss = 0
        all_preds = []
        all_labels = []
        
        with torch.no_grad():
            for images, masks in val_loader:
                images = images.to(DEVICE, non_blocking=True)
                masks = masks.to(DEVICE, non_blocking=True)
                outputs = model(images)
                
                loss = criterion(outputs, masks)
                val_loss += loss.item()
                
                # Get predictions
                preds = outputs.argmax(dim=1).cpu().numpy()
                all_preds.extend(preds.flatten())
                all_labels.extend(masks.cpu().numpy().flatten())
        
        avg_val_loss = val_loss / len(val_loader)
        eval_time = time.time() - eval_start
        
        # Calculate metrics
        from sklearn.metrics import f1_score, precision_score, recall_score
        
        all_preds = np.array(all_preds)
        all_labels = np.array(all_labels)
        
        if (all_labels == 1).sum() > 0:
            f1 = f1_score(all_labels, all_preds, pos_label=1, zero_division=0)
            precision = precision_score(all_labels, all_preds, pos_label=1, zero_division=0)
            recall = recall_score(all_labels, all_preds, pos_label=1, zero_division=0)
            
            # IoU
            intersection = np.sum((all_preds == 1) & (all_labels == 1))
            union = np.sum((all_preds == 1) | (all_labels == 1))
            iou = intersection / (union + 1e-8)
        else:
            f1 = precision = recall = iou = 0.0
        
        train_times.append(train_time)
        eval_times.append(eval_time)
        
        # Print epoch summary
        print(f"\nEpoch {epoch+1}/{EPOCHS}:")
        print(f"  Train Loss: {avg_train_loss:.4f} ({train_time:.1f}s)")
        print(f"  Val Loss: {avg_val_loss:.4f}, F1: {f1:.4f}, IoU: {iou:.4f} ({eval_time:.2f}s)")
        print(f"  Precision: {precision:.4f}, Recall: {recall:.4f}")
        print(f"  LR: {scheduler.get_last_lr()[0]:.6f}")
        
        # Save best model
        improved = False
        if f1 > best_f1 or (f1 == best_f1 and iou > best_iou):
            if f1 > best_f1:
                best_f1 = f1
            if iou > best_iou:
                best_iou = iou
            if avg_val_loss < best_loss:
                best_loss = avg_val_loss
            patience_counter = 0
            improved = True
            
            save_path = OUTPUT_DIR / "advanced_model.pth"
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'val_loss': avg_val_loss,
                'f1': f1,
                'iou': iou,
                'precision': precision,
                'recall': recall,
                'train_loss': avg_train_loss,
            }, save_path)
            print(f"  â˜… Best model saved! (F1={f1:.4f}, IoU={iou:.4f}, Val Loss={avg_val_loss:.4f})")
        else:
            patience_counter += 1
        
        scheduler.step()
        
        # Early stopping
        if patience_counter >= patience:
            print(f"\nEarly stopping at epoch {epoch+1}")
            break
    
    # Training complete
    avg_train_time = np.mean(train_times)
    avg_eval_time = np.mean(eval_times)
    
    print("\n" + "=" * 60)
    print("Training Complete!")
    print(f"Best F1 Score: {best_f1:.4f}")
    print(f"Best IoU: {best_iou:.4f}")
    print(f"Best validation loss: {best_loss:.4f}")
    print(f"Average train time: {avg_train_time:.2f}s/epoch")
    print(f"Average eval time: {avg_eval_time:.2f}s/epoch")
    print(f"Model saved to: {OUTPUT_DIR / 'advanced_model.pth'}")
    print("=" * 60)


if __name__ == "__main__":
    try:
        train()
    except KeyboardInterrupt:
        print("\nTraining interrupted by user")
    except Exception as e:
        print(f"\nError during training: {e}")
        import traceback
        traceback.print_exc()
