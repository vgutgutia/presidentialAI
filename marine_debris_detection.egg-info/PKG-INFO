Metadata-Version: 2.4
Name: marine-debris-detection
Version: 1.0.0
Summary: AI-powered marine debris detection using satellite imagery
Home-page: https://github.com/yourusername/marine-debris-detection
Author: Your Name
Author-email: your.email@example.com
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Scientific/Engineering :: Image Recognition
Classifier: Topic :: Scientific/Engineering :: GIS
Requires-Python: >=3.10
Description-Content-Type: text/markdown
License-File: LICENSE
Dynamic: author
Dynamic: author-email
Dynamic: classifier
Dynamic: description
Dynamic: description-content-type
Dynamic: home-page
Dynamic: license-file
Dynamic: requires-python
Dynamic: summary

# ğŸŒŠ Marine Debris Early Warning System

**AI-powered satellite imagery analysis for detecting offshore marine debris accumulation zones.**

*Presidential AI Challenge Submission*

---

## ğŸ¯ What This Does

This system automatically detects marine debris (plastics, waste) floating in ocean waters using free Sentinel-2 satellite imagery. It produces:

- **Heatmaps** showing debris probability across ocean areas
- **Ranked hotspot lists** with GPS coordinates for cleanup prioritization  
- **GIS-ready outputs** (GeoTIFF, GeoJSON) for integration with mapping tools

---

## ğŸ–¥ï¸ System Requirements

This project is optimized for **Apple Silicon (M4 Max)** but works on any system:

| Component | Minimum | Recommended |
|-----------|---------|-------------|
| Python | 3.10+ | 3.11 |
| RAM | 16GB | 32GB+ |
| Storage | 20GB | 50GB+ |
| GPU | None (CPU works) | Apple M4 Max / NVIDIA GPU |

---

## ğŸš€ Quick Start (5 Minutes)

### Step 1: Clone and Setup

```bash
# Clone your repository
git clone https://github.com/YOUR_USERNAME/marine-debris-detection.git
cd marine-debris-detection

# Create virtual environment
python3 -m venv venv
source venv/bin/activate

# Install dependencies (optimized for Apple Silicon)
pip install --upgrade pip
pip install -r requirements.txt

# Install the package
pip install -e .
```

### Step 2: Download Training Data

```bash
# Download MARIDA dataset (~2GB)
python scripts/download_marida.py
```

### Step 3: Train the Model

```bash
# Train with default settings (uses MPS on M4 Max automatically)
python scripts/train.py

# Or with custom settings
python scripts/train.py --epochs 50 --batch-size 8
```

### Step 4: Run Detection on New Imagery

```bash
# Run inference on a Sentinel-2 image
python scripts/predict.py --input path/to/sentinel2_image.tif --output outputs/

# Run on sample data (included)
python scripts/predict.py --demo
```

---

## ğŸ“ Project Structure

```
marine-debris-detection/
â”œâ”€â”€ README.md                 # You are here
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ setup.py                  # Package installation
â”œâ”€â”€ config.yaml              # Main configuration
â”‚
â”œâ”€â”€ src/                     # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data/               # Data loading & preprocessing
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ dataset.py      # PyTorch dataset
â”‚   â”‚   â”œâ”€â”€ preprocessing.py # Image preprocessing
â”‚   â”‚   â””â”€â”€ download.py     # Data download utilities
â”‚   â”‚
â”‚   â”œâ”€â”€ models/             # Neural network models
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ segformer.py    # SegFormer for multispectral
â”‚   â”‚
â”‚   â”œâ”€â”€ training/           # Training utilities
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ trainer.py      # Training loop
â”‚   â”‚   â”œâ”€â”€ losses.py       # Loss functions
â”‚   â”‚   â””â”€â”€ metrics.py      # Evaluation metrics
â”‚   â”‚
â”‚   â”œâ”€â”€ inference/          # Prediction pipeline
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ predictor.py    # Inference engine
â”‚   â”‚
â”‚   â””â”€â”€ utils/              # Utilities
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ geo.py          # Geospatial utilities
â”‚       â””â”€â”€ visualization.py # Plotting functions
â”‚
â”œâ”€â”€ scripts/                 # Entry point scripts
â”‚   â”œâ”€â”€ download_marida.py  # Download training data
â”‚   â”œâ”€â”€ train.py            # Train the model
â”‚   â”œâ”€â”€ predict.py          # Run inference
â”‚   â””â”€â”€ evaluate.py         # Evaluate model
â”‚
â”œâ”€â”€ data/                    # Data directory (created automatically)
â”‚   â”œâ”€â”€ marida/             # MARIDA dataset
â”‚   â””â”€â”€ raw/                # Raw Sentinel-2 scenes
â”‚
â”œâ”€â”€ outputs/                 # Output directory
â”‚   â”œâ”€â”€ models/             # Saved model weights
â”‚   â”œâ”€â”€ predictions/        # Prediction outputs
â”‚   â””â”€â”€ logs/               # Training logs
â”‚
â””â”€â”€ notebooks/              # Jupyter notebooks
    â””â”€â”€ exploration.ipynb   # Data exploration
```

---

## ğŸ“Š Data

### MARIDA Dataset

We use the [MARIDA](https://github.com/marine-debris/marine-debris.github.io) (Marine Debris Archive) dataset:

- **Source**: Sentinel-2 multispectral satellite imagery
- **Annotations**: Pixel-level semantic labels
- **Classes**: Marine Debris, Sargassum, Ships, Foam, Water types, etc.
- **Size**: ~2GB

### Sentinel-2 Bands Used

| Band | Name | Resolution | Use |
|------|------|------------|-----|
| B2 | Blue | 10m | Water penetration |
| B3 | Green | 10m | Debris detection |
| B4 | Red | 10m | Debris detection |
| B8 | NIR | 10m | Vegetation/debris separation |
| B11 | SWIR1 | 20m | Material discrimination |
| B12 | SWIR2 | 20m | Material discrimination |

---

## ğŸ§  Model Architecture

**SegFormer-B2** adapted for 6-band multispectral input:

```
Input (6 bands) â†’ Patch Embedding â†’ Mix Transformer Encoder â†’ MLP Decoder â†’ Output (2 classes)
```

Key modifications:
- First convolution layer accepts 6 channels instead of 3
- Pretrained weights loaded for all other layers
- Binary output: debris vs. non-debris

---

## âš™ï¸ Configuration

Edit `config.yaml` to customize:

```yaml
# Model settings
model:
  backbone: "mit_b2"          # SegFormer variant
  num_classes: 2              # Binary classification
  
# Training settings  
training:
  epochs: 100
  batch_size: 8               # Increase for more VRAM
  learning_rate: 0.0001
  
# Data settings
data:
  patch_size: 256
  bands: ["B2", "B3", "B4", "B8", "B11", "B12"]

# Inference settings
inference:
  confidence_threshold: 0.5   # Minimum confidence for detection
  min_area_m2: 10000          # Minimum debris area (mÂ²)
```

---

## ğŸ”§ Detailed Usage

### Training

```bash
# Basic training
python scripts/train.py

# Custom training
python scripts/train.py \
    --epochs 100 \
    --batch-size 8 \
    --lr 0.0001 \
    --checkpoint outputs/models/checkpoint.pth  # Resume training

# Monitor training (in another terminal)
tensorboard --logdir outputs/logs
```

### Inference

```bash
# Single image
python scripts/predict.py \
    --input data/raw/my_scene.tif \
    --output outputs/predictions/ \
    --model outputs/models/best_model.pth

# Batch processing
python scripts/predict.py \
    --input-dir data/raw/scenes/ \
    --output outputs/predictions/ \
    --model outputs/models/best_model.pth

# With visualization
python scripts/predict.py \
    --input data/raw/my_scene.tif \
    --output outputs/predictions/ \
    --visualize
```

### Evaluation

```bash
# Evaluate on test set
python scripts/evaluate.py \
    --model outputs/models/best_model.pth \
    --data-dir data/marida/test
```

---

## ğŸ“ˆ Outputs

### 1. Probability Heatmap (GeoTIFF)
```
outputs/predictions/scene_name_heatmap.tif
```
- Georeferenced probability map (0-1)
- Same CRS as input imagery
- Viewable in QGIS, ArcGIS, Google Earth

### 2. Hotspot Polygons (GeoJSON)
```
outputs/predictions/scene_name_hotspots.geojson
```
```json
{
  "type": "FeatureCollection",
  "features": [{
    "type": "Feature",
    "properties": {
      "confidence": 0.87,
      "area_m2": 45000,
      "centroid_lat": 37.7892,
      "centroid_lon": -122.4324
    },
    "geometry": { "type": "Polygon", "coordinates": [...] }
  }]
}
```

### 3. Ranked Hotspot CSV
```
outputs/predictions/scene_name_hotspots.csv
```
```csv
rank,latitude,longitude,area_m2,confidence,timestamp
1,37.7892,-122.4324,45000,0.87,2024-01-15T10:30:00Z
2,37.8123,-122.3987,32000,0.82,2024-01-15T10:30:00Z
```

---

## ğŸ Apple Silicon Optimization

This code automatically uses **MPS (Metal Performance Shaders)** on Apple Silicon:

```python
# Automatic device selection in code
device = (
    "mps" if torch.backends.mps.is_available() 
    else "cuda" if torch.cuda.is_available() 
    else "cpu"
)
```

**Performance tips for M4 Max:**
- Batch size 8-16 works well
- Mixed precision training is supported
- ~2-3x faster than CPU-only

---

## ğŸ”¬ API Usage (For Developers)

```python
from src.inference import MarineDebrisPredictor
from src.data import load_sentinel2_scene

# Initialize predictor
predictor = MarineDebrisPredictor(
    model_path="outputs/models/best_model.pth",
    device="mps"  # or "cuda", "cpu"
)

# Load and predict
scene = load_sentinel2_scene("path/to/scene.tif")
results = predictor.predict(scene)

# Access results
heatmap = results["probability_map"]      # numpy array
hotspots = results["hotspots"]            # GeoDataFrame
metadata = results["metadata"]            # dict

# Save outputs
predictor.save_results(results, "outputs/predictions/")
```

---

## ğŸ§ª Testing

```bash
# Run all tests
pytest tests/ -v

# Run with coverage
pytest tests/ --cov=src --cov-report=html
```

---

## ğŸ“š References

- [MARIDA Dataset Paper](https://arxiv.org/abs/2110.01975)
- [SegFormer Paper](https://arxiv.org/abs/2105.15203)
- [Sentinel-2 User Guide](https://sentinel.esa.int/web/sentinel/user-guides/sentinel-2-msi)

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) file.

---

## ğŸ™ Acknowledgments

- MARIDA dataset creators
- European Space Agency (Sentinel-2 data)
- Hugging Face (SegFormer implementation)

---

*Built for the Presidential AI Challenge â€” Protecting Our Oceans with AI* ğŸŒŠ
